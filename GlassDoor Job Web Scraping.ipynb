{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from nltk.corpus import stopwords\n",
    "import plotly.express as p\n",
    "import warnings\n",
    "import gc\n",
    "import random\n",
    "import numpy as np  \n",
    "random_state = 123\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import httplib2\n",
    "import urllib\n",
    "import requests\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_to_website = 'https://www.glassdoor.com/Job/data-scientist-visa-sponsorship-jobs-SRCH_KO0,31.htm'\n",
    "html = requests.get(link_to_website)\n",
    "bsobj = soup(html.content, 'lxml')\n",
    "\n",
    "links = []\n",
    "for i in bsobj.findAll('div', attrs={\"class\": 'jobContainer'}):\n",
    "    print(i) \n",
    "#     link = 'https://www.glassdoor.co.in' + i.a['href']\n",
    "#     links.append(link)\n",
    "# print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminated before reaching target number of jobs. Needed 2, got 0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This line will open a new chrome window and start the scraping.\n",
    "df = get_jobs(\"data scientist\", 2, False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_df = pd.read_csv(\"C:/Current_Work/IGEmail_email_lifecoach_30_hashtag.csv\")\n",
    "scrape_df.to_csv(\"C:/Current_Work/scraped_Instagram_Profiles_Emails.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### adding options to the webdriver\n",
    "chromeOptions = Options()\n",
    "chromeOptions.add_argument(\"--kiosk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list for saving texts\n",
    "\n",
    "def scrape_Glosbe_Health_Data(list_of_search_words):\n",
    "    kin_list =[]\n",
    "    eng_list = []\n",
    "\n",
    "    option = Options()\n",
    "    option.add_argument('headless')\n",
    "\n",
    "\n",
    "    # Loop through the list of search words # input the text to search in the search box\n",
    "    for search_words in list_of_search_words:\n",
    "        # Define chrome webDriver\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=option)\n",
    "\n",
    "        # Use the get method to load the url\n",
    "        driver.get(r'https://glosbe.com/en/rw')\n",
    "        driver.maximize_window()\n",
    "\n",
    "        # Find the search box element by its name\n",
    "        ele = driver.find_element_by_name('q')\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Clear any text in the search box\n",
    "        ele.clear()\n",
    "        time.sleep(3)\n",
    "        ele.send_keys(search_words)\n",
    "        # Submit the form\n",
    "        ele.send_keys(Keys.RETURN)\n",
    "\n",
    "        # Use a While loop to scroll down the page\n",
    "        while True:\n",
    "            # find the elements which has tag name div\n",
    "            Divs = driver.find_element_by_tag_name('div').text\n",
    "\n",
    "            # if the div has does not have the text \"Load more\" break the loop\n",
    "            if 'LOAD MORE' not in Divs:\n",
    "                print(\"Web Scraping Complete\")\n",
    "                break \n",
    "                \n",
    "            # otherwise find the element which has an id== \"tmem_more\", which is the button to load more pages using an xpath expression\n",
    "            else:\n",
    "                element = driver.find_element_by_xpath(\n",
    "                        '//button[@id=\"tmem__more\"]')\n",
    "\n",
    "                # Scroll the page till you get to the element\n",
    "                desired_y = (element.size['height'] / 2) + element.location['y']\n",
    "                window_h = driver.execute_script('return window.innerHeight')\n",
    "                window_y = driver.execute_script('return window.pageYOffset')\n",
    "                current_y = (window_h / 2) + window_y\n",
    "                scroll_y_by = desired_y - current_y\n",
    "                driver.execute_script(\"window.scrollBy(0, arguments[0]);\", scroll_y_by)\n",
    "\n",
    "                # Wait for the page to load after getting to the element\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Click the button to load more pages\n",
    "                element = driver.find_element_by_xpath(\n",
    "                        '//button[@id=\"tmem__more\"]').click()\n",
    "                    \n",
    "                # wait for the page to load after clicking the button\n",
    "                time.sleep(3)\n",
    "\n",
    "                # continue the loop\n",
    "                continue\n",
    "\n",
    "        # pass the html code to BeautifulSoup and parse it using html parser    \n",
    "        page_source_view = driver.page_source\n",
    "        soup = BeautifulSoup(page_source_view, 'html.parser')\n",
    "\n",
    "\n",
    "        ## Find all the divs with class attribute=\"w-1/2 relative pl-2\" which is Kinyarwanda Text\n",
    "        kin_text_finder = soup.find_all(\"div\", attrs={\"class\": 'w-1/2 relative pl-2'})\n",
    "        for kin_text in kin_text_finder:\n",
    "            kin_list.append(kin_text.text.strip())\n",
    "\n",
    "\n",
    "\n",
    "        ## Find all the divs with class attribute=\"w-1/2 pr-2\" which is English Text\n",
    "        eng_text_finder = soup.find_all(\"div\", attrs={\"class\": 'w-1/2 pr-2'})\n",
    "        for eng_text in eng_text_finder:\n",
    "            eng_list.append(eng_text.text.strip())\n",
    "\n",
    "    ### append lists to dataframes\n",
    "    kin_df = pd.DataFrame(kin_list, columns=['kin_text'])\n",
    "    eng_df = pd.DataFrame(eng_list, columns=['eng_text'])\n",
    "\n",
    "    return kin_df, eng_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Health Data From Glosbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping texts that has to do with diseases, infections, sickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_list = ['Alzheimer', 'HIV', 'COVID', 'EBOLA', 'VIRUS', 'pneumonia',\n",
    "                'flu', 'asthma', 'ulcer', 'coli', 'Gonorrhea', 'Syphilis',\n",
    "                'cancer', 'leprosy', 'epilepsy', 'bacteria', 'Diarrhoea',\n",
    " 'Smallpox', 'malaria', 'measles', 'chickenpox', 'yellow fever', \n",
    " 'cholera', 'fever', 'typhoid', 'tuberculosis', 'diabetes', 'heart disease',\n",
    "    'lung disease', 'cancer', 'stroke', 'kidney disease', 'liver disease',\n",
    "'heart attack', 'high blood pressure', 'polio', 'Meningitis',\n",
    "'tuberculosis', 'herpes', 'gonorrhea', 'hepatitis','syphilis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping text that has to do with the systems of the body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_of_body = [\n",
    " 'arteries', 'veins', 'muscle', 'lungs', 'liver', 'kidney', 'plasma', \n",
    " 'platelets', 'red cells', 'white cells', 'hormones', ' pulmonary', \n",
    " 'pancreas', 'bladder', ''\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping text that has to do with Child bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_bearing = [\n",
    "'placenta', 'MRI', ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Scraping Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "kin, eng = scrape_Glosbe_Health_Data(search_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 Peter 3:8) For instance, when a family of needy Christians had to move to a new area for health reasons, fellow believers there let them use a house rent-free for six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food, water, shelter, medical care, and emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He told the commissioner that we had just pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although his condition was serious and some do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For example, a woman who had spent all her res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are You Prepared for a Medical Emergency?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Outline your theocratic background as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>What a joy for them to build houses and live i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6 Some health experts recommend prayer as trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>A chronic health problem can make you feel as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>(1 Peter 3:8) For instance, when a family of n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng_text\n",
       "0    Food, water, shelter, medical care, and emotio...\n",
       "1    He told the commissioner that we had just pers...\n",
       "2    Although his condition was serious and some do...\n",
       "3    For example, a woman who had spent all her res...\n",
       "4            Are You Prepared for a Medical Emergency?\n",
       "..                                                 ...\n",
       "395  Outline your theocratic background as well as ...\n",
       "396  What a joy for them to build houses and live i...\n",
       "397  6 Some health experts recommend prayer as trea...\n",
       "398  A chronic health problem can make you feel as ...\n",
       "399  (1 Peter 3:8) For instance, when a family of n...\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1a. Data Visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "01e7be8b0026bafd93b41fb415e9db8b0da6a3f8cb0b48eca390d7b6a0c27d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
