{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import plotly.express as p\n",
    "import warnings\n",
    "import gc\n",
    "import random\n",
    "import numpy as np  \n",
    "random_state = 123\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup\n",
    "import httplib2\n",
    "import urllib\n",
    "import requests\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory reduction helper function:\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:  # columns\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:  # numerics\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n",
    "            end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def varname(variable):\n",
    "    for name in list(globals().keys()):\n",
    "        expression = f'id({name})'\n",
    "        if id(variable) == eval(expression):\n",
    "            return name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tourism_data(scraped_tourism_data):\n",
    "    # lower text\n",
    "    text = text.lower()\n",
    "    #removing square brackets\n",
    "    text = re.sub('[.*?]', '', text)\n",
    "    text = re.sub('\\+', '', text)\n",
    "    #removing hyperlinks and emails\n",
    "    text = re.sub('https?://S+|www.S+', '', text)\n",
    "    text = text.rstrip('.com')\n",
    "    text = text.rstrip('@gmail')\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    #removing puncuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\n",
    "    'https://app.memrise.com/course/89247/kinyarwanda-phrases/1/')\n",
    "\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tourism_data():\n",
    "    kin_list = []\n",
    "    eng_list = []\n",
    "\n",
    "    for i in range(1, 27):\n",
    "        resp = requests.get('https://app.memrise.com/course/89247/kinyarwanda-phrases/'+ str(i)+'/')\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        kin_title = soup.find_all(\"div\", attrs={\"class\": 'col_a col text'})\n",
    "        for kin_text in kin_title:\n",
    "            kin_list.append(kin_text.text)\n",
    "\n",
    "        eng_title = soup.find_all(\"div\", attrs={\"class\": 'col_b col text'})\n",
    "        for eng_text in eng_title:\n",
    "            eng_list.append(eng_text.text)\n",
    "\n",
    "\n",
    "    ### append lists to dataframes\n",
    "    kin_df =  pd.DataFrame(kin_list, columns=['kin_text'])\n",
    "    eng_df = pd.DataFrame(eng_list, columns = ['eng_text'])\n",
    "\n",
    "    return kin_df, eng_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_health_data():\n",
    "    kin_list = []\n",
    "    eng_list = []\n",
    "\n",
    "    for i in range(27, 34):\n",
    "        resp = requests.get(\n",
    "            'https://app.memrise.com/course/89247/kinyarwanda-phrases/' + str(i)+'/')\n",
    "\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        kin_title = soup.find_all(\"div\", attrs={\"class\": 'col_a col text'})\n",
    "        for kin_text in kin_title:\n",
    "            kin_list.append(kin_text.text)\n",
    "\n",
    "        eng_title = soup.find_all(\"div\", attrs={\"class\": 'col_b col text'})\n",
    "        for eng_text in eng_title:\n",
    "            eng_list.append(eng_text.text)\n",
    "\n",
    "\n",
    "    ##### Another webpage on memrise\n",
    "    resp = requests.get(\n",
    "        'https://app.memrise.com/course/1341863/bits-of-kinyarwanda/8/')\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    \n",
    "    kin_title = soup.find_all(\"div\", attrs={\"class\": 'col_a col text'})\n",
    "    for kin_text in kin_title:\n",
    "        kin_list.append(kin_text.text)\n",
    "\n",
    "    eng_title = soup.find_all(\"div\", attrs={\"class\": 'col_b col text'})\n",
    "    for eng_text in eng_title:\n",
    "        eng_list.append(eng_text.text)\n",
    "\n",
    "    ### append lists to dataframes\n",
    "    kin_df = pd.DataFrame(kin_list, columns=['kin_text'])\n",
    "    eng_df = pd.DataFrame(eng_list, columns=['eng_text'])\n",
    "\n",
    "    return kin_df, eng_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### adding options to the webdriver\n",
    "chromeOptions = Options()\n",
    "chromeOptions.add_argument(\"--kiosk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 106.0.5249\n",
      "Get LATEST chromedriver version for 106.0.5249 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\106.0.5249.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get('https://www.sportybet.com/ng/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list for saving texts\n",
    "\n",
    "def scrape_Glosbe_Health_Data(list_of_search_words):\n",
    "    kin_list =[]\n",
    "    eng_list = []\n",
    "\n",
    "    option = Options()\n",
    "    option.add_argument('headless')\n",
    "\n",
    "\n",
    "    # Loop through the list of search words # input the text to search in the search box\n",
    "    for search_words in list_of_search_words:\n",
    "        # Define chrome webDriver\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=option)\n",
    "\n",
    "        # Use the get method to load the url\n",
    "        driver.get(r'https://glosbe.com/en/rw')\n",
    "        driver.maximize_window()\n",
    "\n",
    "        # Find the search box element by its name\n",
    "        ele = driver.find_element_by_name('q')\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Clear any text in the search box\n",
    "        ele.clear()\n",
    "        time.sleep(3)\n",
    "        ele.send_keys(search_words)\n",
    "        # Submit the form\n",
    "        ele.send_keys(Keys.RETURN)\n",
    "\n",
    "        # Use a While loop to scroll down the page\n",
    "        while True:\n",
    "            # find the elements which has tag name div\n",
    "            Divs = driver.find_element_by_tag_name('div').text\n",
    "\n",
    "            # if the div has does not have the text \"Load more\" break the loop\n",
    "            if 'LOAD MORE' not in Divs:\n",
    "                print(\"Web Scraping Complete\")\n",
    "                break \n",
    "                \n",
    "            # otherwise find the element which has an id== \"tmem_more\", which is the button to load more pages using an xpath expression\n",
    "            else:\n",
    "                element = driver.find_element_by_xpath(\n",
    "                        '//button[@id=\"tmem__more\"]')\n",
    "\n",
    "                # Scroll the page till you get to the element\n",
    "                desired_y = (element.size['height'] / 2) + element.location['y']\n",
    "                window_h = driver.execute_script('return window.innerHeight')\n",
    "                window_y = driver.execute_script('return window.pageYOffset')\n",
    "                current_y = (window_h / 2) + window_y\n",
    "                scroll_y_by = desired_y - current_y\n",
    "                driver.execute_script(\"window.scrollBy(0, arguments[0]);\", scroll_y_by)\n",
    "\n",
    "                # Wait for the page to load after getting to the element\n",
    "                time.sleep(3)\n",
    "\n",
    "                # Click the button to load more pages\n",
    "                element = driver.find_element_by_xpath(\n",
    "                        '//button[@id=\"tmem__more\"]').click()\n",
    "                    \n",
    "                # wait for the page to load after clicking the button\n",
    "                time.sleep(3)\n",
    "\n",
    "                # continue the loop\n",
    "                continue\n",
    "\n",
    "        # pass the html code to BeautifulSoup and parse it using html parser    \n",
    "        page_source_view = driver.page_source\n",
    "        soup = BeautifulSoup(page_source_view, 'html.parser')\n",
    "\n",
    "\n",
    "        ## Find all the divs with class attribute=\"w-1/2 relative pl-2\" which is Kinyarwanda Text\n",
    "        kin_text_finder = soup.find_all(\"div\", attrs={\"class\": 'w-1/2 relative pl-2'})\n",
    "        for kin_text in kin_text_finder:\n",
    "            kin_list.append(kin_text.text.strip())\n",
    "\n",
    "\n",
    "\n",
    "        ## Find all the divs with class attribute=\"w-1/2 pr-2\" which is English Text\n",
    "        eng_text_finder = soup.find_all(\"div\", attrs={\"class\": 'w-1/2 pr-2'})\n",
    "        for eng_text in eng_text_finder:\n",
    "            eng_list.append(eng_text.text.strip())\n",
    "\n",
    "    ### append lists to dataframes\n",
    "    kin_df = pd.DataFrame(kin_list, columns=['kin_text'])\n",
    "    eng_df = pd.DataFrame(eng_list, columns=['eng_text'])\n",
    "\n",
    "    return kin_df, eng_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Health Data From Glosbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping texts that has to do with diseases, infections, sickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_list = ['Alzheimer', 'HIV', 'COVID', 'EBOLA', 'VIRUS', 'pneumonia',\n",
    "                'flu', 'asthma', 'ulcer', 'coli', 'Gonorrhea', 'Syphilis',\n",
    "                'cancer', 'leprosy', 'epilepsy', 'bacteria', 'Diarrhoea',\n",
    " 'Smallpox', 'malaria', 'measles', 'chickenpox', 'yellow fever', \n",
    " 'cholera', 'fever', 'typhoid', 'tuberculosis', 'diabetes', 'heart disease',\n",
    "    'lung disease', 'cancer', 'stroke', 'kidney disease', 'liver disease',\n",
    "'heart attack', 'high blood pressure', 'polio', 'Meningitis',\n",
    "'tuberculosis', 'herpes', 'gonorrhea', 'hepatitis','syphilis']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping text that has to do with the systems of the body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems_of_body = [\n",
    " 'arteries', 'veins', 'muscle', 'lungs', 'liver', 'kidney', 'plasma', \n",
    " 'platelets', 'red cells', 'white cells', 'hormones', ' pulmonary', \n",
    " 'pancreas', 'bladder', ''\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping text that has to do with Child bearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_bearing = [\n",
    "'placenta', 'MRI', ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Scraping Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\ORAEGBU AYOMIDE\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "kin, eng = scrape_Glosbe_Health_Data(search_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 Peter 3:8) For instance, when a family of needy Christians had to move to a new area for health reasons, fellow believers there let them use a house rent-free for six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food, water, shelter, medical care, and emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He told the commissioner that we had just pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although his condition was serious and some do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For example, a woman who had spent all her res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are You Prepared for a Medical Emergency?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Outline your theocratic background as well as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>What a joy for them to build houses and live i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6 Some health experts recommend prayer as trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>A chronic health problem can make you feel as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>(1 Peter 3:8) For instance, when a family of n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng_text\n",
       "0    Food, water, shelter, medical care, and emotio...\n",
       "1    He told the commissioner that we had just pers...\n",
       "2    Although his condition was serious and some do...\n",
       "3    For example, a woman who had spent all her res...\n",
       "4            Are You Prepared for a Medical Emergency?\n",
       "..                                                 ...\n",
       "395  Outline your theocratic background as well as ...\n",
       "396  What a joy for them to build houses and live i...\n",
       "397  6 Some health experts recommend prayer as trea...\n",
       "398  A chronic health problem can make you feel as ...\n",
       "399  (1 Peter 3:8) For instance, when a family of n...\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1a. Data Visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "01e7be8b0026bafd93b41fb415e9db8b0da6a3f8cb0b48eca390d7b6a0c27d60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
